{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Task 4: Machine Learning & Statistical Modeling\n",
        "\n",
        "## Objective\n",
        "Build and evaluate predictive models that form the core of a dynamic, risk-based pricing system.\n",
        "\n",
        "## Modeling Goals:\n",
        "\n",
        "1. **Claim Severity Prediction (Risk Model)**: For policies that have a claim, build a model to predict the TotalClaims amount.\n",
        "   - Target Variable: TotalClaims (on subset where claims > 0)\n",
        "   - Evaluation Metrics: RMSE, R²\n",
        "\n",
        "2. **Premium Optimization (Pricing Framework)**: Develop a machine learning model to predict an appropriate premium.\n",
        "   - Target Variable: CalculatedPremiumPerTerm or TotalPremium\n",
        "   - Evaluation Metrics: RMSE, R²\n",
        "\n",
        "3. **Claim Probability Prediction (Advanced)**: Build a model to predict the probability of a claim occurring.\n",
        "   - Target Variable: Binary indicator (HasClaim)\n",
        "   - Evaluation Metrics: Accuracy, Precision, Recall, F1, ROC-AUC\n",
        "\n",
        "4. **Zipcode-Level Linear Regression**: For each zipcode, fit a linear regression model that predicts total claims.\n",
        "\n",
        "## Models to Implement:\n",
        "- Linear Regression\n",
        "- Random Forest\n",
        "- XGBoost\n",
        "\n",
        "## Model Interpretability:\n",
        "- Feature Importance Analysis\n",
        "- SHAP (SHapley Additive exPlanations) values\n",
        "- Business interpretation of important features\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Import necessary libraries\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# Import custom modules\n",
        "import sys\n",
        "sys.path.append('../src')\n",
        "from data_processing import load_and_validate_data, engineer_features\n",
        "from modeling import (\n",
        "    prepare_features_for_modeling, encode_categorical_features,\n",
        "    impute_missing_values, train_linear_regression, train_random_forest,\n",
        "    train_xgboost, get_feature_importance, calculate_shap_values\n",
        ")\n",
        "from utils import calculate_claim_frequency, calculate_claim_severity\n",
        "\n",
        "# Machine Learning\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score\n",
        "\n",
        "# Set display options\n",
        "pd.set_option('display.max_columns', None)\n",
        "pd.set_option('display.max_rows', 100)\n",
        "pd.set_option('display.float_format', lambda x: '%.4f' % x)\n",
        "\n",
        "# Set plotting style\n",
        "sns.set_style(\"whitegrid\")\n",
        "plt.rcParams['figure.figsize'] = (12, 6)\n",
        "plt.rcParams['font.size'] = 10\n",
        "\n",
        "print(\"Libraries imported successfully!\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. Data Loading and Preparation\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Load the data\n",
        "data_path = '../data/raw/insurance_data.csv'  # Update this path\n",
        "\n",
        "try:\n",
        "    df = load_and_validate_data(data_path)\n",
        "    print(f\"Data loaded successfully!\")\n",
        "    print(f\"Shape: {df.shape}\")\n",
        "except FileNotFoundError:\n",
        "    print(f\"Data file not found at {data_path}\")\n",
        "    print(\"Please update the data_path variable with the correct path to your insurance data.\")\n",
        "    print(\"\\nCreating sample data for demonstration...\")\n",
        "    # Create sample data\n",
        "    np.random.seed(42)\n",
        "    n_samples = 10000\n",
        "    df = pd.DataFrame({\n",
        "        'PolicyID': range(n_samples),\n",
        "        'TransactionMonth': pd.date_range('2014-02-01', periods=n_samples, freq='D'),\n",
        "        'Province': np.random.choice(['Gauteng', 'Western Cape', 'KwaZulu-Natal', 'Eastern Cape'], n_samples),\n",
        "        'PostalCode': np.random.choice([1000, 2000, 3000, 4000, 5000, 6000], n_samples),\n",
        "        'Gender': np.random.choice(['Male', 'Female'], n_samples),\n",
        "        'VehicleType': np.random.choice(['Sedan', 'SUV', 'Hatchback', 'Coupe'], n_samples),\n",
        "        'Make': np.random.choice(['Toyota', 'Ford', 'BMW', 'Mercedes', 'VW'], n_samples),\n",
        "        'RegistrationYear': np.random.randint(2000, 2020, n_samples),\n",
        "        'SumInsured': np.random.uniform(50000, 500000, n_samples),\n",
        "        'TotalPremium': np.random.uniform(5000, 50000, n_samples),\n",
        "        'CalculatedPremiumPerTerm': np.random.uniform(4000, 45000, n_samples),\n",
        "        'TotalClaims': np.random.exponential(10000, n_samples) * (np.random.random(n_samples) < 0.3),\n",
        "        'CustomValueEstimate': np.random.uniform(50000, 500000, n_samples)\n",
        "    })\n",
        "    print(\"Sample dataframe created for demonstration purposes.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Engineer features\n",
        "df = engineer_features(df)\n",
        "print(f\"After feature engineering: {df.shape}\")\n",
        "print(f\"\\nNew features created:\")\n",
        "new_features = ['VehicleAge', 'HasClaim', 'PremiumToSumInsuredRatio', 'LossRatio', \n",
        "                'VehicleValueCategory', 'PremiumCategory']\n",
        "for feat in new_features:\n",
        "    if feat in df.columns:\n",
        "        print(f\"  - {feat}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. Model 1: Claim Severity Prediction (Risk Model)\n",
        "\n",
        "**Objective**: Predict TotalClaims amount for policies that have claims.\n",
        "**Target**: TotalClaims (on subset where TotalClaims > 0)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Prepare data for claim severity prediction (only policies with claims)\n",
        "df_claims = df[df['TotalClaims'] > 0].copy()\n",
        "print(f\"Policies with claims: {len(df_claims):,} ({len(df_claims)/len(df)*100:.2f}%)\")\n",
        "\n",
        "if len(df_claims) < 100:\n",
        "    print(\"⚠ Warning: Very few policies with claims. Model may not perform well.\")\n",
        "else:\n",
        "    # Prepare features\n",
        "    X_sev, y_sev, cat_cols_sev, num_cols_sev = prepare_features_for_modeling(\n",
        "        df_claims, \n",
        "        target_col='TotalClaims',\n",
        "        exclude_cols=['PolicyID', 'UnderwrittenCoverID', 'TotalPremium', 'CalculatedPremiumPerTerm']\n",
        "    )\n",
        "    \n",
        "    # Encode categorical features\n",
        "    X_sev_encoded, encoder_sev = encode_categorical_features(X_sev, cat_cols_sev, method='onehot')\n",
        "    \n",
        "    # Impute missing values\n",
        "    X_sev_processed, imputers_sev = impute_missing_values(X_sev_encoded)\n",
        "    \n",
        "    # Train-test split\n",
        "    X_train_sev, X_test_sev, y_train_sev, y_test_sev = train_test_split(\n",
        "        X_sev_processed, y_sev, test_size=0.2, random_state=42\n",
        "    )\n",
        "    \n",
        "    print(f\"\\nTraining set: {len(X_train_sev):,} samples\")\n",
        "    print(f\"Test set: {len(X_test_sev):,} samples\")\n",
        "    print(f\"Features: {X_train_sev.shape[1]}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Train models for claim severity prediction\n",
        "severity_models = {}\n",
        "\n",
        "if len(df_claims) >= 100:\n",
        "    # Linear Regression\n",
        "    print(\"=\"*80)\n",
        "    print(\"Training Linear Regression for Claim Severity...\")\n",
        "    print(\"=\"*80)\n",
        "    severity_models['linear'] = train_linear_regression(\n",
        "        X_train_sev, y_train_sev, X_test_sev, y_test_sev\n",
        "    )\n",
        "    \n",
        "    # Random Forest\n",
        "    print(\"\\n\" + \"=\"*80)\n",
        "    print(\"Training Random Forest for Claim Severity...\")\n",
        "    print(\"=\"*80)\n",
        "    severity_models['rf'] = train_random_forest(\n",
        "        X_train_sev, y_train_sev, X_test_sev, y_test_sev,\n",
        "        is_classification=False, n_estimators=100\n",
        "    )\n",
        "    \n",
        "    # XGBoost\n",
        "    print(\"\\n\" + \"=\"*80)\n",
        "    print(\"Training XGBoost for Claim Severity...\")\n",
        "    print(\"=\"*80)\n",
        "    severity_models['xgb'] = train_xgboost(\n",
        "        X_train_sev, y_train_sev, X_test_sev, y_test_sev,\n",
        "        is_classification=False, n_estimators=100\n",
        "    )\n",
        "    \n",
        "    print(\"\\n\" + \"=\"*80)\n",
        "    print(\"CLAIM SEVERITY MODEL COMPARISON\")\n",
        "    print(\"=\"*80)\n",
        "    comparison_sev = pd.DataFrame({\n",
        "        'Model': [m['model_name'] for m in severity_models.values()],\n",
        "        'Test RMSE': [m['test_rmse'] for m in severity_models.values()],\n",
        "        'Test R²': [m['test_r2'] for m in severity_models.values()],\n",
        "        'Test MAE': [m['test_mae'] for m in severity_models.values()]\n",
        "    })\n",
        "    print(comparison_sev.to_string(index=False))\n",
        "else:\n",
        "    print(\"Insufficient data for claim severity modeling.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Prepare data for premium prediction\n",
        "target_premium = 'CalculatedPremiumPerTerm' if 'CalculatedPremiumPerTerm' in df.columns else 'TotalPremium'\n",
        "print(f\"Using target: {target_premium}\")\n",
        "\n",
        "X_prem, y_prem, cat_cols_prem, num_cols_prem = prepare_features_for_modeling(\n",
        "    df,\n",
        "    target_col=target_premium,\n",
        "    exclude_cols=['PolicyID', 'UnderwrittenCoverID', 'TotalClaims']\n",
        ")\n",
        "\n",
        "# Encode categorical features\n",
        "X_prem_encoded, encoder_prem = encode_categorical_features(X_prem, cat_cols_prem, method='onehot')\n",
        "\n",
        "# Impute missing values\n",
        "X_prem_processed, imputers_prem = impute_missing_values(X_prem_encoded)\n",
        "\n",
        "# Train-test split\n",
        "X_train_prem, X_test_prem, y_train_prem, y_test_prem = train_test_split(\n",
        "    X_prem_processed, y_prem, test_size=0.2, random_state=42\n",
        ")\n",
        "\n",
        "print(f\"\\nTraining set: {len(X_train_prem):,} samples\")\n",
        "print(f\"Test set: {len(X_test_prem):,} samples\")\n",
        "print(f\"Features: {X_train_prem.shape[1]}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Train models for premium prediction\n",
        "premium_models = {}\n",
        "\n",
        "print(\"=\"*80)\n",
        "print(\"Training Linear Regression for Premium Prediction...\")\n",
        "print(\"=\"*80)\n",
        "premium_models['linear'] = train_linear_regression(\n",
        "    X_train_prem, y_train_prem, X_test_prem, y_test_prem\n",
        ")\n",
        "\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"Training Random Forest for Premium Prediction...\")\n",
        "print(\"=\"*80)\n",
        "premium_models['rf'] = train_random_forest(\n",
        "    X_train_prem, y_train_prem, X_test_prem, y_test_prem,\n",
        "    is_classification=False, n_estimators=100\n",
        ")\n",
        "\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"Training XGBoost for Premium Prediction...\")\n",
        "print(\"=\"*80)\n",
        "premium_models['xgb'] = train_xgboost(\n",
        "    X_train_prem, y_train_prem, X_test_prem, y_test_prem,\n",
        "    is_classification=False, n_estimators=100\n",
        ")\n",
        "\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"PREMIUM PREDICTION MODEL COMPARISON\")\n",
        "print(\"=\"*80)\n",
        "comparison_prem = pd.DataFrame({\n",
        "    'Model': [m['model_name'] for m in premium_models.values()],\n",
        "    'Test RMSE': [m['test_rmse'] for m in premium_models.values()],\n",
        "    'Test R²': [m['test_r2'] for m in premium_models.values()],\n",
        "    'Test MAE': [m['test_mae'] for m in premium_models.values()]\n",
        "})\n",
        "print(comparison_prem.to_string(index=False))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4. Model 3: Claim Probability Prediction (Binary Classification)\n",
        "\n",
        "**Objective**: Predict the probability of a claim occurring.\n",
        "**Target**: HasClaim (binary: 0 = no claim, 1 = has claim)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Prepare data for claim probability prediction (binary classification)\n",
        "if 'HasClaim' not in df.columns:\n",
        "    df['HasClaim'] = (df['TotalClaims'] > 0).astype(int)\n",
        "\n",
        "print(f\"Claim frequency: {df['HasClaim'].mean():.4f} ({df['HasClaim'].mean()*100:.2f}%)\")\n",
        "print(f\"Policies with claims: {df['HasClaim'].sum():,}\")\n",
        "print(f\"Policies without claims: {(df['HasClaim'] == 0).sum():,}\")\n",
        "\n",
        "X_prob, y_prob, cat_cols_prob, num_cols_prob = prepare_features_for_modeling(\n",
        "    df,\n",
        "    target_col='HasClaim',\n",
        "    exclude_cols=['PolicyID', 'UnderwrittenCoverID', 'TotalClaims']\n",
        ")\n",
        "\n",
        "# Encode categorical features\n",
        "X_prob_encoded, encoder_prob = encode_categorical_features(X_prob, cat_cols_prob, method='onehot')\n",
        "\n",
        "# Impute missing values\n",
        "X_prob_processed, imputers_prob = impute_missing_values(X_prob_encoded)\n",
        "\n",
        "# Train-test split\n",
        "X_train_prob, X_test_prob, y_train_prob, y_test_prob = train_test_split(\n",
        "    X_prob_processed, y_prob, test_size=0.2, random_state=42, stratify=y_prob\n",
        ")\n",
        "\n",
        "print(f\"\\nTraining set: {len(X_train_prob):,} samples\")\n",
        "print(f\"Test set: {len(X_test_prob):,} samples\")\n",
        "print(f\"Features: {X_train_prob.shape[1]}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Train models for claim probability prediction\n",
        "probability_models = {}\n",
        "\n",
        "print(\"=\"*80)\n",
        "print(\"Training Random Forest for Claim Probability...\")\n",
        "print(\"=\"*80)\n",
        "probability_models['rf'] = train_random_forest(\n",
        "    X_train_prob, y_train_prob, X_test_prob, y_test_prob,\n",
        "    is_classification=True, n_estimators=100\n",
        ")\n",
        "\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"Training XGBoost for Claim Probability...\")\n",
        "print(\"=\"*80)\n",
        "probability_models['xgb'] = train_xgboost(\n",
        "    X_train_prob, y_train_prob, X_test_prob, y_test_prob,\n",
        "    is_classification=True, n_estimators=100\n",
        ")\n",
        "\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"CLAIM PROBABILITY MODEL COMPARISON\")\n",
        "print(\"=\"*80)\n",
        "comparison_prob = pd.DataFrame({\n",
        "    'Model': [m['model_name'] for m in probability_models.values()],\n",
        "    'Test Accuracy': [m['test_accuracy'] for m in probability_models.values()],\n",
        "    'Test Precision': [m['test_precision'] for m in probability_models.values()],\n",
        "    'Test Recall': [m['test_recall'] for m in probability_models.values()],\n",
        "    'Test F1': [m['test_f1'] for m in probability_models.values()]\n",
        "})\n",
        "if 'test_roc_auc' in probability_models['rf']:\n",
        "    comparison_prob['Test ROC-AUC'] = [m.get('test_roc_auc', np.nan) for m in probability_models.values()]\n",
        "print(comparison_prob.to_string(index=False))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5. Model 4: Zipcode-Level Linear Regression\n",
        "\n",
        "**Objective**: For each zipcode, fit a linear regression model that predicts total claims.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Zipcode-level linear regression\n",
        "if 'PostalCode' in df.columns:\n",
        "    zipcode_models = {}\n",
        "    zipcode_results = []\n",
        "    \n",
        "    # Get zipcodes with sufficient data\n",
        "    zipcode_counts = df['PostalCode'].value_counts()\n",
        "    valid_zipcodes = zipcode_counts[zipcode_counts >= 50].index.tolist()\n",
        "    \n",
        "    print(f\"Fitting linear regression models for {len(valid_zipcodes)} zipcodes...\")\n",
        "    print(f\"(Minimum 50 samples per zipcode required)\\n\")\n",
        "    \n",
        "    for zipcode in valid_zipcodes[:20]:  # Limit to top 20 for performance\n",
        "        zipcode_data = df[df['PostalCode'] == zipcode].copy()\n",
        "        \n",
        "        if len(zipcode_data) < 50:\n",
        "            continue\n",
        "        \n",
        "        # Prepare features (aggregate by zipcode)\n",
        "        features = ['TotalPremium', 'SumInsured']\n",
        "        if 'CustomValueEstimate' in zipcode_data.columns:\n",
        "            features.append('CustomValueEstimate')\n",
        "        \n",
        "        X_zip = zipcode_data[features].values\n",
        "        y_zip = zipcode_data['TotalClaims'].values\n",
        "        \n",
        "        # Train linear regression\n",
        "        try:\n",
        "            model_zip = LinearRegression()\n",
        "            model_zip.fit(X_zip, y_zip)\n",
        "            \n",
        "            # Predictions\n",
        "            y_pred_zip = model_zip.predict(X_zip)\n",
        "            \n",
        "            # Metrics\n",
        "            rmse = np.sqrt(mean_squared_error(y_zip, y_pred_zip))\n",
        "            r2 = r2_score(y_zip, y_pred_zip)\n",
        "            \n",
        "            zipcode_models[zipcode] = model_zip\n",
        "            zipcode_results.append({\n",
        "                'PostalCode': zipcode,\n",
        "                'SampleSize': len(zipcode_data),\n",
        "                'RMSE': rmse,\n",
        "                'R²': r2,\n",
        "                'Coefficients': model_zip.coef_.tolist()\n",
        "            })\n",
        "        except Exception as e:\n",
        "            print(f\"Error fitting model for zipcode {zipcode}: {str(e)}\")\n",
        "    \n",
        "    zipcode_results_df = pd.DataFrame(zipcode_results)\n",
        "    print(\"\\nZipcode-Level Linear Regression Results:\")\n",
        "    print(zipcode_results_df.to_string(index=False))\n",
        "else:\n",
        "    print(\"PostalCode column not found in dataset.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Feature importance for best premium prediction model\n",
        "best_prem_model_name = comparison_prem.loc[comparison_prem['Test R²'].idxmax(), 'Model']\n",
        "best_prem_model_key = [k for k, v in premium_models.items() if v['model_name'] == best_prem_model_name][0]\n",
        "best_prem_model = premium_models[best_prem_model_key]['model']\n",
        "\n",
        "print(f\"Analyzing feature importance for: {best_prem_model_name}\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "# Get feature importance\n",
        "feature_importance = get_feature_importance(best_prem_model, X_train_prem.columns.tolist(), top_n=15)\n",
        "\n",
        "if not feature_importance.empty:\n",
        "    print(\"\\nTop 15 Most Important Features:\")\n",
        "    print(feature_importance.to_string(index=False))\n",
        "    \n",
        "    # Visualize feature importance\n",
        "    fig, ax = plt.subplots(figsize=(12, 8))\n",
        "    ax.barh(range(len(feature_importance)), feature_importance['importance'].values, edgecolor='black', alpha=0.7)\n",
        "    ax.set_yticks(range(len(feature_importance)))\n",
        "    ax.set_yticklabels(feature_importance['feature'].values)\n",
        "    ax.set_xlabel('Feature Importance', fontweight='bold')\n",
        "    ax.set_title(f'Feature Importance - {best_prem_model_name}', fontweight='bold')\n",
        "    ax.grid(True, alpha=0.3, axis='x')\n",
        "    plt.tight_layout()\n",
        "    plt.savefig('../figures/feature_importance_premium.png', dpi=300, bbox_inches='tight')\n",
        "    plt.show()\n",
        "else:\n",
        "    print(\"Could not extract feature importance.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# SHAP Analysis for model interpretability\n",
        "try:\n",
        "    print(\"=\"*80)\n",
        "    print(\"SHAP Analysis for Model Interpretability\")\n",
        "    print(\"=\"*80)\n",
        "    \n",
        "    # Use best premium model\n",
        "    shap_results = calculate_shap_values(\n",
        "        best_prem_model,\n",
        "        X_test_prem.sample(min(100, len(X_test_prem))),\n",
        "        max_samples=100\n",
        "    )\n",
        "    \n",
        "    if shap_results:\n",
        "        print(\"\\nTop Features by Mean Absolute SHAP Value:\")\n",
        "        print(shap_results['feature_importance'].head(15).to_string(index=False))\n",
        "        \n",
        "        # Visualize SHAP summary\n",
        "        try:\n",
        "            import shap\n",
        "            fig, ax = plt.subplots(figsize=(12, 8))\n",
        "            shap.summary_plot(\n",
        "                shap_results['shap_values'],\n",
        "                shap_results['X_sample'],\n",
        "                plot_type=\"bar\",\n",
        "                max_display=15,\n",
        "                show=False\n",
        "            )\n",
        "            plt.tight_layout()\n",
        "            plt.savefig('../figures/shap_summary.png', dpi=300, bbox_inches='tight')\n",
        "            plt.show()\n",
        "        except Exception as e:\n",
        "            print(f\"Could not create SHAP plot: {str(e)}\")\n",
        "    else:\n",
        "        print(\"SHAP analysis not available.\")\n",
        "        \n",
        "except Exception as e:\n",
        "    print(f\"Error in SHAP analysis: {str(e)}\")\n",
        "    print(\"Make sure SHAP is installed: pip install shap\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 7. Model Interpretability & Business Insights\n",
        "\n",
        "Interpret the top features and their business implications.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Business interpretation of feature importance\n",
        "print(\"=\"*80)\n",
        "print(\"BUSINESS INTERPRETATION OF MODEL FEATURES\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "if not feature_importance.empty:\n",
        "    top_features = feature_importance.head(10)\n",
        "    \n",
        "    print(\"\\nTop 10 Features Influencing Premium Prediction:\\n\")\n",
        "    for idx, row in top_features.iterrows():\n",
        "        feature = row['feature']\n",
        "        importance = row['importance']\n",
        "        \n",
        "        print(f\"{idx+1}. {feature} (Importance: {importance:.4f})\")\n",
        "        \n",
        "        # Provide business interpretation\n",
        "        if 'VehicleAge' in feature or 'RegistrationYear' in feature:\n",
        "            print(\"   → Older vehicles may require higher premiums due to increased risk\")\n",
        "        elif 'Province' in feature:\n",
        "            print(\"   → Geographic location significantly impacts premium pricing\")\n",
        "        elif 'VehicleType' in feature or 'Make' in feature:\n",
        "            print(\"   → Vehicle characteristics are key drivers of insurance costs\")\n",
        "        elif 'SumInsured' in feature or 'CustomValueEstimate' in feature:\n",
        "            print(\"   → Vehicle value directly influences premium calculations\")\n",
        "        elif 'Gender' in feature:\n",
        "            print(\"   → Gender may be a factor (ensure regulatory compliance)\")\n",
        "        elif 'PostalCode' in feature:\n",
        "            print(\"   → Location granularity affects risk assessment\")\n",
        "        print()\n",
        "    \n",
        "    print(\"\\nKey Business Recommendations:\")\n",
        "    print(\"1. Focus pricing strategy on top 5-10 features identified by the model\")\n",
        "    print(\"2. Consider risk-based adjustments for high-importance features\")\n",
        "    print(\"3. Monitor feature importance over time as market conditions change\")\n",
        "    print(\"4. Use SHAP values to explain individual premium predictions to customers\")\n",
        "    print(\"5. Validate model predictions against business rules and regulatory requirements\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 8. Summary and Model Comparison\n",
        "\n",
        "Compare all models and provide final recommendations.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Final summary\n",
        "print(\"=\"*100)\n",
        "print(\"MODELING SUMMARY REPORT\")\n",
        "print(\"=\"*100)\n",
        "\n",
        "print(\"\\n1. CLAIM SEVERITY PREDICTION (Risk Model)\")\n",
        "print(\"-\" * 100)\n",
        "if severity_models:\n",
        "    best_sev = max(severity_models.items(), key=lambda x: x[1]['test_r2'])\n",
        "    print(f\"Best Model: {best_sev[1]['model_name']}\")\n",
        "    print(f\"  Test RMSE: {best_sev[1]['test_rmse']:.2f}\")\n",
        "    print(f\"  Test R²: {best_sev[1]['test_r2']:.4f}\")\n",
        "    print(f\"  Test MAE: {best_sev[1]['test_mae']:.2f}\")\n",
        "else:\n",
        "    print(\"Models not trained (insufficient data)\")\n",
        "\n",
        "print(\"\\n2. PREMIUM OPTIMIZATION (Pricing Framework)\")\n",
        "print(\"-\" * 100)\n",
        "if premium_models:\n",
        "    best_prem = max(premium_models.items(), key=lambda x: x[1]['test_r2'])\n",
        "    print(f\"Best Model: {best_prem[1]['model_name']}\")\n",
        "    print(f\"  Test RMSE: {best_prem[1]['test_rmse']:.2f}\")\n",
        "    print(f\"  Test R²: {best_prem[1]['test_r2']:.4f}\")\n",
        "    print(f\"  Test MAE: {best_prem[1]['test_mae']:.2f}\")\n",
        "\n",
        "print(\"\\n3. CLAIM PROBABILITY PREDICTION (Binary Classification)\")\n",
        "print(\"-\" * 100)\n",
        "if probability_models:\n",
        "    best_prob = max(probability_models.items(), key=lambda x: x[1]['test_f1'])\n",
        "    print(f\"Best Model: {best_prob[1]['model_name']}\")\n",
        "    print(f\"  Test Accuracy: {best_prob[1]['test_accuracy']:.4f}\")\n",
        "    print(f\"  Test F1 Score: {best_prob[1]['test_f1']:.4f}\")\n",
        "    if 'test_roc_auc' in best_prob[1]:\n",
        "        print(f\"  Test ROC-AUC: {best_prob[1]['test_roc_auc']:.4f}\")\n",
        "\n",
        "print(\"\\n4. ZIPCODE-LEVEL LINEAR REGRESSION\")\n",
        "print(\"-\" * 100)\n",
        "if 'zipcode_results_df' in locals() and not zipcode_results_df.empty:\n",
        "    avg_r2 = zipcode_results_df['R²'].mean()\n",
        "    print(f\"Average R² across zipcodes: {avg_r2:.4f}\")\n",
        "    print(f\"Number of zipcodes modeled: {len(zipcode_results_df)}\")\n",
        "\n",
        "print(\"\\n\" + \"=\"*100)\n",
        "print(\"MODELING COMPLETE!\")\n",
        "print(\"=\"*100)\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
